import re
import aisuite as ai
from dotenv import load_dotenv
import json
import os
import ast
from typing import List, Dict, Any
from HELPERS import *

_ = load_dotenv()
client = ai.Client()


def clean_json_string(content: str) -> str:
    """Removes markdown formatting to ensure clean JSON parsing."""
    return content.replace("```json", "").replace("```", "").strip()


def run_single_hara(user_prompt: str, model: str) -> Dict[str, Any]:
    """
    Runs the full HARA chain on a SINGLE model and returns the dictionary.
    """
    print(f"\n>>> ==== STARTING RUN ON MODEL: {model} ====\n")

    # Local storage for this specific run
    run_data = {
        "model_used": model,
        "system": "",
        "persons": [],
        "hazards": [],
        "harms_analysis": [],
        "scenarios": []
    }

    # 1. Extract System
    msg = [
        {"role": "system", "content": "You are an expert at HARA analysis provided with a system description. Return "
                                      "a concise system description in the form of a short paragraph only containing "
                                      "senctences which mention every technical detail of the system."},
        {"role": "user", "content": f"User Prompt: {user_prompt}\n\nExtract the system description concisely."}
    ]
    run_data["system"] = run_chat_hara(msg, model, temperature=0)

    # 2. Identify Persons at Risk
    msg = [
        {"role": "system", "content": "Identify persons at risk. Output a JSON list of strings."},
        {"role": "user",
         "content": f"System: {run_data['system']}\n\nReturn JSON list of person in PLURAL e.g. ['Operators', 'Bystanders']"}
    ]
    run_data["persons"] = run_chat_hara(msg, model, expected_format="json")
    print(f"   -> Persons identified: {run_data['persons']}")

    # 3. Identify Hazards
    msg = [
        {"role": "system", "content": "Identify standard hazard categories."},
        {"role": "user",
         "content": f"""
         System: {run_data['system']}

         Task: Identify potential hazards.

         CONSTRAINT: 
         - Return ONLY standard, atomic hazard categories (e.g., 'Crushing', 'Shearing', 'Fire', 'Electric Shock'). 
         - Do NOT include 'from...' or 'due to...' descriptions.
         - Keep them as single words or short standard phrases.

         Return JSON list of strings.
         """}
    ]
    run_data["hazards"] = run_chat_hara(msg, model, expected_format="json", temperature=0)
    print(f"   -> Hazards identified: {run_data['hazards']}")

    # 4. Analyze Harms

    if run_data["persons"] and run_data["hazards"]:
        harm_queries = []
        for person in run_data["persons"]:
            for hazard in run_data["hazards"]:
                query = f"How could the system harm {person} through {hazard}?"
                harm_queries.append(query)
        print(f"   -> Generated {len(harm_queries)} theoretical harm queries.")

        # Filter out nonsensical phrases
        msg_filter = [
            {"role": "system",
             "content": f"""You are a skeptical Senior Safety Auditor.
            
            # YOUR MISSION
            The input list was generated by a dumb script that matches *everyone* with *everything*. 
            Your job is to AGGRESSIVELY FILTER this list. You must discard any scenario that does not make operational sense.

            # IMMEDIATE REJECTION RULES (Apply these strictly)
            1. **The "Teleportation" Rule (Proximity):** - If the person (e.g., 'Remote Supervisor', 'Office Clerk') is not physically inside the danger zone, REJECT it.
               - Hazards like 'Crushing', 'Shearing', 'Entanglement' require physical contact.

            2. **The "Mechanism" Rule (Causality):** - Does the hazard *actually* apply to the person's role? 
               - BAD: "How could the system harm a Bystander through High Voltage?" -> REJECT (High voltage is inside the machine casing; bystanders don't open panels).
               - GOOD: "How could the system harm a Maintenance Tech through High Voltage?" -> KEEP (They open panels).

            3. **The "Abstract" Rule:**
               - Do not allow abstract concepts to cause physical trauma directly without a mechanism.
               - BAD: "How could the system harm an Operator through Software?" -> REJECT (Software can't hit you).
               - GOOD: "How could the system harm an Operator through Unexpected Movement?" -> KEEP.

            # EXAMPLES
            - INPUT: "How could the system harm a Remote IT Support through Shearing?" 
            -> ACTION: DELETE (No proximity).
            - INPUT: "How could the system harm a Bystander through Hydraulic Fluid Leak?" 
            -> ACTION: DELETE (Unlikely exposure, low severity).
            - INPUT: "How could the system harm an Operator through Crushing?" 
            -> ACTION: KEEP (Valid risk).

            # OUTPUT
            Return a JSON of strings containing ONLY the scenarios that survived the audit. 
            Do NOT explain why. Just return the valid JSON of strings.
            """
             },
            {"role": "user", "content": f"""
            # CONTEXT
            System Description: {run_data['system']}

            # INPUT LIST (Theoretical Scenarios)
            {json.dumps(harm_queries)}
            """}
        ]
        # Analyze filtered harm queries
        valid_queries = run_chat_hara(msg_filter, model, expected_format="json", temperature=0)
        print(f"   -> Valid harm queries after filtering: {len(valid_queries)}")

        if valid_queries:
            msg_analyze = [
                {"role": "system", "content": """fYou are a Safety Expert. Describe specific physical harms.
                
                TASK: 
                - I have a list of CONFIRMED valid risk scenarios.
                - For each one, describe the specific harm that occurs.
                
                OUTPUT JSON:
                [
                    {{
                        "guide_phrase": "The input string...",
                        "harm_mechanism": "Describe HOW it happens (e.g. 'Hand trapped in gears')",
                        "injury_type": "Medical term (e.g. 'Amputation', '3rd deg burn')",
                        "severity": "High/Medium/Low"
                    }}
                ]
                """},
                {"role": "user", "content": f"""
                System: {run_data['system']}

                INPUT SCENARIOS:
                {json.dumps(valid_queries)}
                """}
            ]

            run_data["harms_analysis"] = run_chat_hara(msg_analyze, model, expected_format="json", temperature=0)
            print(f"   -> Detailed analysis completed for {len(run_data['harms_analysis'])} items.")
            for harm in run_data["harms_analysis"]:
                print(
                    f"      - {harm['guide_phrase']} => {harm['injury_type']} via {harm['harm_mechanism']} (Severity: {harm['severity']}) \n")

        else:
            print("  -> No valid harm scenarios identified after filtering.)")
            run_data["harms_analysis"] = []

        if run_data["harms_analysis"]:
            print("   -> Running Final Quality Assurance Check...")
            msg = [
                {"role": "system",
                 "content": f"""You are a Lead Safety Engineer performing final Quality Assurance on a HARA report.
                
                 # YOUR TASK
                Review each entry for logical consistency and operational realism.

                # REJECTION CRITERIA (Delete entries that violate these):
                1. **Role Mismatch:** e.g., 'Supervisors' or 'Bystanders' getting 'Ergonomic injuries' (they don't perform repetitive tasks) or 'Entanglement' (they don't touch parts).
                2. **Facility vs System:** e.g., 'Slipping on wet floor' is a facility issue, NOT a robot issue, unless the robot leaked the fluid.
                3. **Improbable Access:** e.g., 'Operator' getting 'Electric Shock' from standard buttons (standard controls are low voltage/insulated).
                4. **Severity Mismatch:** e.g., 'Noise' causing 'Death'.

                # OUTPUT
                Return a cleaned JSON list containing ONLY the entries that passed QA. 
                (You may lightly edit the 'harm_mechanism' to be more precise if needed).
                """},
                {"role": "user", "content": f"""
                # CONTEXT
                System: {run_data['system']}

                # DRAFT REPORT ENTRIES
                {json.dumps(run_data["harms_analysis"])}"""}
            ]

            cleaned_harms = run_chat_hara(msg, model, expected_format="json", temperature=0)

            if cleaned_harms and len(cleaned_harms) > 0:
                print(f"   -> QA removed {len(run_data['harms_analysis']) - len(cleaned_harms)} low-quality entries.")
                run_data["harms_analysis"] = cleaned_harms
            else:
                print(
                    "   -> QA Warning: All entries were rejected (or parsing failed). Keeping original list for review.")

        # 5. Scenarios (Strict JSON)
    msg = [
        {"role": "system", "content": f"""Generate 3 refined failure scenarios in JSON.
        OUTPUT JSON:
        [ {{"title": "...", 
            "narrative": "...", 
            "consequence": "..."}} ]
        """},
        {"role": "user", "content": f"""
        Based on:
        System: {run_data['system']}
        Harms: {json.dumps(run_data['harms_analysis'])}"""}
    ]
    run_data["scenarios"] = run_chat_hara(msg, model, expected_format="json", temperature=0)
    for scenario in run_data["scenarios"]:
        print(f"   -> Scenario generated: {scenario['title']}  - {scenario['narrative']}\n")

    print(f"<<< ==== COMPLETED RUN ON {model} ====")
    return run_data


def synthesize_consensus(results_list: List[Dict], judge_model: str = "openai:gpt-4o") -> Dict[str, Any]:
    """
    Takes N result dictionaries, compares them, and keeps only the findings
    that appear in the majority (conceptually) using an LLM Judge.
    """
    print(f"\nCALCULATE HOW TO USE ANSWERS : {judge_model}...")

    data_str = json.dumps(results_list, indent=2)

    system_prompt = f"""
    You are a an expert in HARA analyis. Your job is to review HARA (Hazard Analysis) reports from muliple different 
    junior analysts.

    TASK:
    - You must generate a FINAL CONSENSUS JSON Report
    - All contradictory information must be refined into a consistent, technically accurate statement
    - For semantical similar responses remove any redundancy while perserving all information which is relevant for the 
      HARA anlysis
    - Any information only mentioned by one anaylysis must be refactored into a consistent statement with respect to 
      all other claims
    - You are not allowed to include incorrect statements or extend them with addtionial information so that they fit
      better

    OUTPUT REQUIREMENTS:
    - Return only a valid JSON object
    - You are not allowed to leave a key out which is defined in the JSON FORMAT section

    JSON FORMAT:
    {{
        "consensus_system_description": "...",
        "verified_persons": ["..."],
        "verified_hazards": ["..."],
        "verified_harms": [ {{"person": "...", "hazard": "...", "harm": "..."}} ],
        "verified_scenarios": [ {{"title": "...", "narrative": "..."}} ]
    }}
    """

    user_prompt = f"""
    Here are the reports from the HARA analysts:

    {data_str}

    Generate the consolidated JSON.
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    final_json = run_chat_hara(messages, model=judge_model, expected_format="json")
    return final_json

def main():
    run_single_hara("A mobile robot (AGV) transports heavy pallets in a warehouse shared with human workers. It has a lifting fork mechanism.", "openai:gpt-4o")

if __name__ == "__main__":
    main()
