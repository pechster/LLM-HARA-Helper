import re
import aisuite as ai  # which imports are really needed?
from dotenv import load_dotenv
import json
import os
import ast
from typing import List, Dict, Any
from HELPERS import *

_ = load_dotenv()
client = ai.Client()


def clean_json_string(content: str) -> str:
    """Removes markdown formatting to ensure clean JSON parsing."""
    return content.replace("```json", "").replace("```", "").strip()


def run_single_hara(user_prompt: str, model: str) -> Dict[str, Any]:
    """
    Runs the full HARA chain on a SINGLE model and returns the dictionary.
    """
    print(f"\n>>> ==== STARTING RUN ON MODEL: {model} ====")

    # Local storage for this specific run
    run_data = {
        "model_used": model,
        "system": "",
        "persons": [],
        "hazards": [],
        "harms_analysis": [],
        "scenarios": []
    }

    # 1. Extract System
    msg = [
        {"role": "system", "content": "Extract the technical system description."},
        {"role": "user", "content": f"User Prompt: {user_prompt}\n\nExtract the system description concisely."}
    ]
    run_data["system"] = run_chat_hara(msg, model)
    print(f"   -> System extracted: {run_data['system']}")

    # 2. Identify Persons at Risk
    msg = [
        {"role": "system", "content": "Identify persons at risk. Output a JSON list of strings."},
        {"role": "user", "content": f"System: {run_data['system']}\n\nReturn JSON list of person in PLURAL e.g. ['Operators', 'Bystanders']"}
    ]
    run_data["persons"] = run_chat_hara(msg, model, expected_format="json")
    print(f"   -> Persons identified: {run_data['persons']}")

    # 3. Identify Hazards
    msg = [
        {"role": "system", "content": "Identify standard hazard categories."},
        {"role": "user",
         "content": f"""
         System: {run_data['system']}
         
         Task: Identify potential hazards.
         
         CONSTRAINT: 
         - Return ONLY standard, atomic hazard categories (e.g., 'Crushing', 'Shearing', 'Fire', 'Electric Shock'). 
         - Do NOT include 'from...' or 'due to...' descriptions.
         - Keep them as single words or short standard phrases.
         
         Return JSON list of strings.
         """}
    ]
    run_data["hazards"] = run_chat_hara(msg, model, expected_format="json")
    print(f"   -> Hazards identified: {run_data['hazards']}")
    
    

    # 4. Analyze Harms
    
    if run_data["persons"] and run_data["hazards"]:
        harm_queries = []
        for person in run_data["persons"]:
            for hazard in run_data["hazards"]:
                query = f"How could the system harm {person} through {hazard}?"
                harm_queries.append(query)
        print(f"   -> Generated {len(harm_queries)} theoretical harm queries.")

        # Filter out nonsensical phrases
        msg_filter = [
            {"role": "system", "content": "You are a skeptical Senior Safety Auditor. Your job is to reject unrealistic, abstract, or highly improbable risk scenarios to prevent database clutter."},
            {"role": "user", "content": f"""
            # CONTEXT
            System Description: {run_data['system']}
            
            # INPUT LIST (Theoretical Scenarios)
            {json.dumps(harm_queries)}

            # YOUR MISSION
            The input list was generated by a dumb script that matches *everyone* with *everything*. 
            Your job is to AGGRESSIVELY FILTER this list. You must discard any scenario that does not make operational sense.

            # IMMEDIATE REJECTION RULES (Apply these strictly)
            1. **The "Teleportation" Rule (Proximity):** - If the person (e.g., 'Remote Supervisor', 'Office Clerk') is not physically inside the danger zone, REJECT it.
               - Hazards like 'Crushing', 'Shearing', 'Entanglement' require physical contact.
            
            2. **The "Mechanism" Rule (Causality):** - Does the hazard *actually* apply to the person's role? 
               - BAD: "How could the system harm a Bystander through High Voltage?" -> REJECT (High voltage is inside the machine casing; bystanders don't open panels).
               - GOOD: "How could the system harm a Maintenance Tech through High Voltage?" -> KEEP (They open panels).

            3. **The "Abstract" Rule:**
               - Do not allow abstract concepts to cause physical trauma directly without a mechanism.
               - BAD: "How could the system harm an Operator through Software?" -> REJECT (Software can't hit you).
               - GOOD: "How could the system harm an Operator through Unexpected Movement?" -> KEEP.

            # EXAMPLES
            - INPUT: "How could the system harm a Remote IT Support through Shearing?" 
            -> ACTION: DELETE (No proximity).
            - INPUT: "How could the system harm a Bystander through Hydraulic Fluid Leak?" 
            -> ACTION: DELETE (Unlikely exposure, low severity).
            - INPUT: "How could the system harm an Operator through Crushing?" 
            -> ACTION: KEEP (Valid risk).

            # OUTPUT
            Return a JSON list of strings containing ONLY the scenarios that survived the audit. 
            Do NOT explain why. Just return the valid strings.
            """}
        ]
        # Analyze filtered harm queries
        valid_queries = run_chat_hara(msg_filter, model, expected_format="json")
        print(f"   -> Valid harm queries after filtering: {len(valid_queries)}")

        if valid_queries:
            msg_analyze = [
                {"role": "system", "content": "You are a Safety Expert. Describe specific physical harms."},
                {"role": "user", "content": f"""
                System: {run_data['system']}

                I have a list of CONFIRMED valid risk scenarios. 
                For each one, describe the specific harm that occurs.

                INPUT SCENARIOS:
                {json.dumps(valid_queries)}

                OUTPUT FORMAT (JSON List of Objects):
                [
                  {{
                    "guide_phrase": "The input string...",
                    "harm_mechanism": "Describe HOW it happens (e.g. 'Hand trapped in gears')",
                    "injury_type": "Medical term (e.g. 'Amputation', '3rd deg burn')",
                    "severity": "High/Medium/Low"
                  }}
                ]
                """}
            ]
            
            run_data["harms_analysis"] = run_chat_hara(msg_analyze, model, expected_format="json")
            print(f"   -> Detailed analysis completed for {len(run_data['harms_analysis'])} items.")
            print(run_data["harms_analysis"])
        
        else:
            print("  -> No valid harm scenarios identified after filtering.)")
            run_data["harms_analysis"] = []
    

    # 5. Scenarios (Strict JSON)
    msg = [
        {"role": "system", "content": "Generate 3 refined failure scenarios in JSON."},
        {"role": "user", "content": f"""
        Based on:
        System: {run_data['system']}
        Harms: {json.dumps(run_data['harms_analysis'])}

        Return a JSON List of objects:
        [ {{"title": "...", "narrative": "...", "consequence": "..."}} ]
        """}
    ]
    run_data["scenarios"] = run_chat_hara(msg, model, expected_format="json")
    print(run_data["scenarios"])

    print(f"<<< ==== COMPLETED RUN ON {model} ====")
    return run_data


def synthesize_consensus(results_list: List[Dict], judge_model: str = "openai:gpt-4o") -> Dict[str, Any]:
    """
    Takes N result dictionaries, compares them, and keeps only the findings
    that appear in the majority (conceptually) using an LLM Judge.
    """
    print(f"\nCALCULATE HOW TO USE ANSWERS : {judge_model}...")

    data_str = json.dumps(results_list, indent=2)

    system_prompt = f"""
    You are a an expert in HARA analyis. Your job is to review HARA (Hazard Analysis) reports from muliple different 
    junior analysts.

    TASK:
    - You must generate a FINAL CONSENSUS JSON Report
    - All contradictory information must be refined into a consistent, technically accurate statement
    - For semantical similar responses remove any redundancy while perserving all information which is relevant for the 
      HARA anlysis
    - Any information only mentioned by one anaylysis must be refactored into a consistent statement with respect to 
      all other claims
    - You are not allowed to include incorrect statements or extend them with addtionial information so that they fit
      better
    
    OUTPUT REQUIREMENTS:
    - Return only a valid JSON object
    - You are not allowed to leave a key out which is defined in the JSON FORMAT section
    
    JSON FORMAT:
    {{
        "consensus_system_description": "...",
        "verified_persons": ["..."],
        "verified_hazards": ["..."],
        "verified_harms": [ {{"person": "...", "hazard": "...", "harm": "..."}} ],
        "verified_scenarios": [ {{"title": "...", "narrative": "..."}} ]
    }}
    """

    user_prompt = f"""
    Here are the reports from the HARA analysts:

    {data_str}

    Generate the consolidated JSON.
    """

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    final_json = run_chat_hara(messages, model=judge_model, expected_format="json")
    return final_json

def main():
    results = run_single_hara("A mobile robot (AGV) transports heavy pallets in a warehouse shared with human workers. It has a lifting fork mechanism.", "openai:gpt-4o-mini")
    filename = "hara_results.json"
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=4)
        

if __name__ == main():
    main()
